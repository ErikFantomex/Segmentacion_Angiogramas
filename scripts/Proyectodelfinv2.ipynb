{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl3+pGWSnPVJE6tJiW3V4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErikFantomex/Segmentacion_Angiogramas/blob/main/Proyectodelfinv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introducción\n",
        "\n",
        "El proyecto explora técnicas de visión por computadora como el modelo de segmentacion gaussiana y el modelo de aprendizaje profundo U-Net. \n",
        "\n",
        "En un esfuerzo por segmentar angiogramas."
      ],
      "metadata": {
        "id": "mGf8DppLnCFn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9EK-PllaKRQw",
        "outputId": "22635d19-647f-48b3-c6c9-055e4221ad6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd  \n",
        "import imageio\n",
        "from skimage import img_as_float32 as as_float\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from scipy.stats import multivariate_normal\n",
        "import cv2\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from skimage import exposure\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.model_selection import KFold,train_test_split \n",
        "from sklearn.metrics import f1_score\n",
        "plt.gray()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Explorando la base de datos \n"
      ],
      "metadata": {
        "id": "IAacNCGjLUs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDtz9_DSK6HZ",
        "outputId": "bb9bc53b-7811-4723-8292-ce8bf92ef9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the dataset\n",
        "#/content/drive/MyDrive/datasets/DB_134/Angiograms\n",
        "\n",
        "path_pairs = list(zip(\n",
        "natsorted(glob('/content/drive/MyDrive/datasets/AngioDB/normal/*.png')),\n",
        "natsorted(glob('/content/drive/MyDrive/datasets/AngioDB/masks/*.png')),\n",
        "))\n",
        "img = np.array([as_float(imageio.imread(ipath)) for ipath, _ in path_pairs])\n",
        "msk = np.array([as_float(imageio.imread(mpath)) for _, mpath in path_pairs])\n",
        "\n",
        "print('There are',img.shape[0],'images and',msk.shape[0],'masks')\n",
        "print('The shape of our data is',img.shape,'and',msk.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCAdosR5LMQH",
        "outputId": "f9e76af5-9e37-4515-c7ed-24b4abc9140c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 135 images and 135 masks\n",
            "The shape of our data is (135, 768, 1024) and (135, 768, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando el conjunto de datos."
      ],
      "metadata": {
        "id": "Rhqvi2FoaYr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = (768,1024)\n",
        "\n",
        "assert img.shape == (135, SIZE[0], SIZE[1])\n",
        "assert msk.shape == (135, SIZE[0], SIZE[1])\n",
        "\n",
        "SCALE = 0.40\n",
        "\n",
        "images = [cv2.resize(img, None, fx=SCALE, fy=SCALE) for img in tqdm(img, 'Resizing Images')]\n",
        "masks1 = [cv2.resize(img, None, fx=SCALE, fy=SCALE) for img in tqdm(msk, 'Resizing Masks')]\n",
        "\n",
        "masks = []#umbralizar la máscara a 0 y 1 ya que después de reescalar la máscara tendrá diferentes valores \n",
        "for i in range(len(masks1)):\n",
        "    mask = cv2.threshold(masks1[i],0,1,cv2.THRESH_BINARY)[1]\n",
        "    masks.append(mask)\n",
        "    \n",
        "print('\\n', img[0].shape, '->', images[0].shape)"
      ],
      "metadata": {
        "id": "_ORHo81eYj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa00b21c-2614-4208-9ecf-286470d4782e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Resizing Images: 100%|██████████| 135/135 [00:00<00:00, 1606.32it/s]\n",
            "Resizing Masks: 100%|██████████| 135/135 [00:00<00:00, 1314.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " (768, 1024) -> (307, 410)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Diviendo dataset"
      ],
      "metadata": {
        "id": "6pAyfikPqqsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "VALIDATION_needed = True \n",
        "def train_test_valid_split(all_X, all_Y,PERC_TRAIN = 0.65,PERC_VALIDATION = 0.14,PERC_TEST = 0.13): \n",
        "    '''\n",
        "    returs the desired data split ( 34 training images, 7 validation and 7 test images)\n",
        "    \n",
        "    params: \n",
        "    - all_X image data\n",
        "    - all_Y mask or ground truth data\n",
        "    - PERC_VALIDATION percentage for validation data\n",
        "    - PERC_TEST percentage for testing data\n",
        "    - PERC_TRAIN percentage for training data\n",
        "    \n",
        "    '''\n",
        "    left_X, valid_X, left_y, valid_y = train_test_split(all_X, all_Y, test_size=PERC_VALIDATION) \n",
        "    train_X, test_X, train_y, test_y = train_test_split(left_X, left_y, test_size=PERC_TEST / (PERC_TEST + PERC_TRAIN)) \n",
        "    return test_X, test_y, train_X, train_y, valid_X, valid_y \n",
        " \n",
        "if VALIDATION_needed: \n",
        "    test_X, test_y, train_X, train_y, valid_X, valid_y = train_test_valid_split(images, masks) \n",
        "else: \n",
        "    train_X, test_X, train_y, test_y = train_test_split(images, masks) "
      ],
      "metadata": {
        "id": "i0OmmS_vYj_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Despues de divir las fotos:',len(train_X),\n",
        "      'training images',len(valid_X),\n",
        "      'validation and',len(test_X),'test images')"
      ],
      "metadata": {
        "id": "78LINFXDYkHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6bbec9a-f2e5-4528-935a-18b33da69c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Despues de divir las fotos: 96 training images 19 validation and 20 test images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metodo de segmentacion gaussiana\n",
        "\n",
        "*  http://www.oranlooney.com/post/ml-from-scratch-part-5-gmm/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zarIjhP4rKqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SR9233T5m-_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GMM_scratch:\n",
        "    '''\n",
        "       \n",
        "        La implementacion de la clase Segmentacion gaussiana esta basada en la funcion homonima sklearn.mixture.GaussianMixture\n",
        "        params: \n",
        "       \n",
        "        data - the image data to train in the EM step of the GMM\n",
        "        numb_components - the number of clusters to train the GMM\n",
        "        init_strategy - method to initialize the means of the GMM. 0 is the normal initialization method\n",
        "        \n",
        "        \n",
        "        fuentes :\n",
        "        https://github.com/ScienceKot/mysklearn/blob/master/Gaussian%20Mixture%20Models/GMM.py\n",
        "        https://stackoverflow.com/questions/44913009/initialize-gmm-using-sklearn-python\n",
        "        https://github.com/SeoHyeong/GMM_image-segmentation/blob/master/GMM_image%20segmentation.ipynb\n",
        "        https://github.com/roger8587/Image-Segmentation-Using-Gaussian-Mixture-Model-with-PyTorch/blob/main/run.ipynb\n",
        "\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    def __init__(self, data, numb_components,init_strategy):#Step1 initialization of the main variables\n",
        "        \n",
        "        self.valuesforplot = []\n",
        "        self.data = data\n",
        "        self.numb_components = numb_components\n",
        "        \n",
        "        self.H = self.data.shape[1]#\n",
        "        self.W = self.data.shape[0]#\n",
        "        \n",
        "        self.lamda = np.ones((self.numb_components))/self.numb_components\n",
        "        self.means = np.zeros((self.numb_components,self.H))\n",
        "        #create distances variable \n",
        "        if(init_strategy == 0):#Inicializacion aleatoria\n",
        "            for i in range(self.numb_components):\n",
        "                soma = random.choice(self.data)\n",
        "                self.means[i] = soma\n",
        "            \n",
        "        else:# Inicializacion kmeans \n",
        "            from sklearn.cluster import KMeans\n",
        "            km = KMeans(numb_components).fit(self.data)\n",
        "            self.means = km.cluster_centers_\n",
        "            \n",
        "        self.covariance = np.zeros((self.numb_components,self.H,self.H))#Creando el arreglo de covarianza con las dimensiones necesarios \n",
        "        self.covariance[:] = np.cov(self.data.T)#Rl arreglo que contiene toda la informacion de covarianza\n",
        "\n",
        "        self.responsavel = np.zeros((self.W, self.numb_components))#responsavel es simplemente la matriz de responsabilidad dado el número de canales y componentes en la matriz\n",
        "        \n",
        "    #-------------------------------------------Norm-Step------------------------------------------------------------     \n",
        "    def normalvariant(self):\n",
        "        '''\n",
        "        Funcion para calcular la distribucion normal , como en la clase GMM en sklearn\n",
        "        '''\n",
        "        numb_components = self.numb_components\n",
        "        self.normal = []\n",
        "        for i in range(numb_components):\n",
        "            self.normal.append(multivariate_normal(mean=self.means[i], cov=self.covariance[i]))\n",
        "    #-------------------------------------------E-Step-------------------------------------------------------------- \n",
        "    def Expectation(self):#necesito entender esta parte\n",
        "        numb_components = self.numb_components\n",
        "        self.normalvariant()\n",
        "        \n",
        "        for i, points in enumerate(self.data):\n",
        "            for j in range(numb_components):\n",
        "                \n",
        "                self.responsavel[i,j] = self.lamda[j]*self.normal[j].pdf(points)#Calculando responsabilidades\n",
        "            self.responsavel[i,:] /= self.responsavel[i, :].sum()#distribution usando los puntos de la distribucion normal \n",
        "                                                                #del vector de caracteristicas\n",
        "            \n",
        "    #-------------------------------------------M-Step---------------------------------------------------------------\n",
        "    def Maximization(self):#necesito entender esta parte\n",
        "        numb_components = self.numb_components\n",
        "\n",
        "        responsavel_sum = self.responsavel.sum(0)\n",
        "        \n",
        "        self.lamda = responsavel_sum/float(self.responsavel.sum())\n",
        "\n",
        "        for i in range(self.numb_components):\n",
        "            self.means[i] = self.responsavel[:,i].dot(self.data)/responsavel_sum[i]\n",
        "            \n",
        "        for i in range(self.numb_components):\n",
        "            temp = np.zeros((self.H, self.H))\n",
        "            for j in range(self.W):\n",
        "                t = self.data[j, :] - self.means[i]\n",
        "                temp += self.responsavel[j,i]*np.outer(t,t)# Creando la matriz de identidad \n",
        "            self.covariance[i] = temp/responsavel_sum[i]#La matrix covariancia para evitar el fallo singularity \n",
        "            \n",
        "        #Reinicio de la covarirancia y la media representadas en el enlace de abajo por si surgen fallos adicionales\n",
        "\n",
        "        #https://stats.stackexchange.com/questions/219302/singularity-issues-in-gaussian-mixture-model\n",
        "        if(np.isnan(self.covariance[i]).any()== True):\n",
        "            self.covariance[i] = np.cov(self.data.T)#calculamos de nuevo  la covariancia \n",
        "                \n",
        "        for i in range(self.numb_components):\n",
        "            soma = random.choice(self.data)\n",
        "            self.means[i] = soma#Media aleatoria\n",
        "            \n",
        "    #-------------------------------------------Train or fit Step----------------------------------------------------- \n",
        "    def fit(self, tolerance=0.01, max_epoch=35):\n",
        "        distance = tolerance\n",
        "        epoch = 0\n",
        "        while ((distance >= tolerance) and (epoch != max_epoch)):\n",
        "            old_means = self.means.copy()\n",
        "            self.Expectation()\n",
        "            self.Maximization()\n",
        "            distance = np.linalg.norm(old_means - self.means)\n",
        "            print(epoch, distance)\n",
        "            epoch += 1\n",
        "            array = np.array([epoch,distance])\n",
        "            self.valuesforplot.append(array)\n",
        "   #-------------------------------------------Likelihood-Step--------------------------------------------------------\n",
        "    def Proba(self,image):\n",
        "    \n",
        "        Probabilities = np.zeros((image.shape[:-1]))\n",
        "        numb_components = self.numb_components\n",
        "        for i in range(numb_components):\n",
        "            Probabilities += self.lamda[i] * multivariate_normal(mean=self.means[i], cov=self.covariance[i]).pdf(image)\n",
        "        return Probabilities "
      ],
      "metadata": {
        "id": "4PuEhI548OPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vector de caracteristicas\n",
        "Un vector de características puede considerarse una colección de características (características importantes de la imagen estudiada) que se extrae y forma de matriz. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oPgS1JQN9Mj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DrrctY_i19VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwygsZSf19Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9aMbf7-GYkXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitectura U-net\n",
        "\n"
      ],
      "metadata": {
        "id": "-kEgcbgm8rbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "#https://github.com/jbrussellai/UWMGI-Pytorch-Unet"
      ],
      "metadata": {
        "id": "DDAZTlPC7Yfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doubleConv(in_c,out_c):\n",
        "  conv = nn.Sequential(nn.Conv2d(in_c,out_c,3),\n",
        "                       ## can even add BatchNorm here and set bias=False in Conv2d()\n",
        "                       nn.ReLU(inplace=True),\n",
        "                       nn.Conv2d(out_c,out_c,3),\n",
        "                       ## can even add BatchNorm here and set bias=False in Conv2d()\n",
        "                       nn.ReLU(inplace=True)\n",
        "                       )\n",
        "  return conv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## here crop_img is not a good resolve as division operation can throw us in some loopholes\n",
        "## so there we 2 crop_img created as per the size and output changed because of the div operation\n",
        "def crop_img(tensor,target_tensor):\n",
        "  target_size = target_tensor.size()[2] # t_s = 100\n",
        "  tensor_size = tensor.size()[2]        # t_s = 135\n",
        "  delta = tensor_size-target_size   \n",
        "  # print(\"delta was : \",delta)           # delta = 35\n",
        "  delta = delta//2                      # delta was 17\n",
        "  # print(\"delta became :\",delta)          \n",
        "  return tensor[:,:,delta:tensor_size-delta-1,delta:tensor_size-delta-1]\n",
        "\n",
        "def crop_img2(tensor,target_tensor):\n",
        "  target_size = target_tensor.size()[2] # t_s = 100\n",
        "  tensor_size = tensor.size()[2]        # t_s = 135\n",
        "  delta = tensor_size-target_size   \n",
        "  # print(\"delta was : \",delta)           # delta = 35\n",
        "  delta = delta//2                      # delta was 17\n",
        "  # print(\"delta became :\",delta)          \n",
        "  return tensor[:,:,delta:tensor_size-delta,delta:tensor_size-delta]"
      ],
      "metadata": {
        "id": "3yjL_eNqLMa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNET,self).__init__()\n",
        "    self.maxPool = nn.MaxPool2d(3,2)\n",
        "\n",
        "    self.down_conv_1 = doubleConv(1,64)\n",
        "    self.down_conv_2 = doubleConv(64,128)\n",
        "    self.down_conv_3 = doubleConv(128,256)\n",
        "    self.down_conv_4 = doubleConv(256,512)\n",
        "    self.down_conv_5 = doubleConv(512,1024)\n",
        "\n",
        "    self.trans_up_1 = nn.ConvTranspose2d(1024,512,2,2)\n",
        "    self.up_conv_1 = doubleConv(1024,512)\n",
        "\n",
        "    self.trans_up_2 = nn.ConvTranspose2d(512,256,2,2)\n",
        "    self.up_conv_2 = doubleConv(512,256)\n",
        "\n",
        "    self.trans_up_3 = nn.ConvTranspose2d(256,128,2,2)\n",
        "    self.up_conv_3 = doubleConv(256,128)\n",
        "\n",
        "    self.trans_up_4 = nn.ConvTranspose2d(128,64,2,2)\n",
        "    self.up_conv_4 = doubleConv(128,64)\n",
        "\n",
        "    self.out = nn.Conv2d(64,2,1)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,image):\n",
        "    # ENCODER DONE\n",
        "    x1 = self.down_conv_1(image)\n",
        "    x2 = self.maxPool(x1)\n",
        "    x3 = self.down_conv_2(x2)\n",
        "    x4 = self.maxPool(x3)\n",
        "    x5 = self.down_conv_3(x4)\n",
        "    x6 = self.maxPool(x5)\n",
        "    x7 = self.down_conv_4(x6)\n",
        "    x8 = self.maxPool(x7)\n",
        "    x9 = self.down_conv_5(x8)\n",
        "    # print(x9.size())\n",
        "\n",
        "    #DECODER\n",
        "    x = self.trans_up_1(x9)\n",
        "    # print(x.size())\n",
        "    y = crop_img(x7,x)\n",
        "    # print(y.size())\n",
        "    # print(torch.cat([x,y],1).size())\n",
        "    x = self.up_conv_1(torch.cat([x,y],1))\n",
        "    # print(x.size())\n",
        "    x = self.trans_up_2(x)\n",
        "    # print(x.size())\n",
        "    # print(x5.size())\n",
        "    y = crop_img(x5,x)\n",
        "    # print(y.size())\n",
        "    x = self.up_conv_2(torch.cat([x,y],1))\n",
        "    print(x.size())\n",
        "    x = self.trans_up_3(x)\n",
        "    y = crop_img(x3,x)\n",
        "    x = self.up_conv_3(torch.cat([x,y],1))\n",
        "\n",
        "    x = self.trans_up_4(x)\n",
        "    y = crop_img2(x1,x)\n",
        "    x = self.up_conv_4(torch.cat([x,y],1))\n",
        "\n",
        "    x = self.out(x)\n",
        "\n",
        "    print(x.size())\n",
        "    return x"
      ],
      "metadata": {
        "id": "ulJrAMPU6kTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.rand((1,1,572,572))\n",
        "model = UNET()\n",
        "print(model(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Rh8agA7kYo",
        "outputId": "5f641e99-28d0-437c-8c11-1e8ba3c5609a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 96, 96])\n",
            "torch.Size([1, 2, 372, 372])\n",
            "tensor([[[[ 0.0168,  0.0142,  0.0176,  ...,  0.0107,  0.0120,  0.0113],\n",
            "          [ 0.0156,  0.0191,  0.0167,  ...,  0.0154,  0.0124,  0.0088],\n",
            "          [ 0.0152,  0.0147,  0.0166,  ...,  0.0159,  0.0185,  0.0120],\n",
            "          ...,\n",
            "          [ 0.0142,  0.0134,  0.0158,  ...,  0.0177,  0.0148,  0.0186],\n",
            "          [ 0.0097,  0.0150,  0.0172,  ...,  0.0130,  0.0142,  0.0158],\n",
            "          [ 0.0121,  0.0174,  0.0112,  ...,  0.0152,  0.0142,  0.0146]],\n",
            "\n",
            "         [[-0.0348, -0.0340, -0.0391,  ..., -0.0330, -0.0365, -0.0288],\n",
            "          [-0.0330, -0.0349, -0.0341,  ..., -0.0356, -0.0356, -0.0296],\n",
            "          [-0.0335, -0.0348, -0.0367,  ..., -0.0301, -0.0376, -0.0301],\n",
            "          ...,\n",
            "          [-0.0289, -0.0334, -0.0330,  ..., -0.0366, -0.0325, -0.0375],\n",
            "          [-0.0286, -0.0339, -0.0311,  ..., -0.0290, -0.0343, -0.0357],\n",
            "          [-0.0297, -0.0334, -0.0322,  ..., -0.0349, -0.0329, -0.0339]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probando parametros de convergencia "
      ],
      "metadata": {
        "id": "Tqx88lphstGw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4WRzrcBLMoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkU5RybPLNN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPDDIq0qLNUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Algoritmo de Ramer–Douglas–Peucker"
      ],
      "metadata": {
        "id": "oeAC6Q0JYOXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    #source: https://karthaus.nl/rdp/\n",
        "\n",
        "\n",
        "    def function DouglasPeucker(PointList[], epsilon)\n",
        "    # Find the point with the maximum distance\n",
        "    dmax = 0\n",
        "    index = 0\n",
        "    end = length(PointList)\n",
        "    for i = 2 to (end - 1) {\n",
        "        d = perpendicularDistance(PointList[i], Line(PointList[1], PointList[end])) \n",
        "        if (d > dmax) {\n",
        "            index = i\n",
        "            dmax = d\n",
        "        }\n",
        "    }\n",
        "\n",
        "    ResultList[] = empty;\n",
        "\n",
        "    # If max distance is greater than epsilon, recursively simplify\n",
        "    if (dmax > epsilon) {\n",
        "        # Recursive call\n",
        "        recResults1[] = DouglasPeucker(PointList[1...index], epsilon)\n",
        "        recResults2[] = DouglasPeucker(PointList[index...end], epsilon)\n",
        "\n",
        "        # Build the result list\n",
        "        ResultList[] = {recResults1[1...length(recResults1) - 1], recResults2[1...length(recResults2)]}\n",
        "    } else {\n",
        "        ResultList[] = {PointList[1], PointList[end]}\n",
        "    }\n",
        "    # Return the result\n",
        "    return ResultList[]\n"
      ],
      "metadata": {
        "id": "NfMJFuRz49qh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7At9EITLNJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTZc8N5iYfXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9lSQ6uNYfdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhnoRXM-Yfk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_dvmDfFYfqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMA718J3YfyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}